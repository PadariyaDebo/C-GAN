{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PadariyaDebo/C-GAN/blob/main/Copy_of_Conditional_GAN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iBQwj3otjCO9"
      },
      "source": [
        "# Conditional GAN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "ioCRm9f7jCPA",
        "outputId": "20699d1f-4603-45eb-a40a-351caf97d832",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31mERROR: Could not find a version that satisfies the requirement tensorflow-gpu==2.0.0-rc0 (from versions: 1.13.1, 1.13.2, 1.14.0, 1.15.0, 1.15.2, 1.15.3, 1.15.4, 1.15.5, 2.0.0, 2.0.1, 2.0.2, 2.0.3, 2.0.4, 2.1.0, 2.1.1, 2.1.2, 2.1.3, 2.1.4, 2.2.0, 2.2.1, 2.2.2, 2.2.3, 2.3.0, 2.3.1, 2.3.2, 2.3.3, 2.3.4, 2.4.0, 2.4.1, 2.4.2, 2.4.3, 2.4.4, 2.5.0, 2.5.1, 2.5.2, 2.5.3, 2.6.0, 2.6.1, 2.6.2, 2.6.3, 2.6.4, 2.6.5, 2.7.0rc0, 2.7.0rc1, 2.7.0, 2.7.1, 2.7.2, 2.7.3, 2.8.0rc0, 2.8.0rc1, 2.8.0, 2.8.1, 2.8.2, 2.9.0rc0, 2.9.0rc1, 2.9.0rc2, 2.9.0, 2.9.1)\u001b[0m\n",
            "\u001b[31mERROR: No matching distribution found for tensorflow-gpu==2.0.0-rc0\u001b[0m\n",
            "`%tensorflow_version` only switches the major version: 1.x or 2.x.\n",
            "You set: `2.x  # Colab only.`. This will be interpreted as: `2.x`.\n",
            "\n",
            "\n",
            "TensorFlow 2.x selected.\n",
            "2.8.2\n"
          ]
        }
      ],
      "source": [
        "# supress warnings\n",
        "# Install TensorFlow\n",
        "!pip install -q tensorflow-gpu==2.0.0-rc0\n",
        "\n",
        "try:\n",
        "  %tensorflow_version 2.x  # Colab only.\n",
        "except Exception:\n",
        "  pass\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import SGD, Adam\n",
        "from matplotlib.pyplot import imread\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import sys, os\n",
        "from tensorflow.keras.optimizers import Adam"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "Rf-P4TRRjCPC",
        "outputId": "6049749a-00b5-4b28-b329-826ab3663d9e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "11501568/11490434 [==============================] - 0s 0us/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 28, 28)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "# import dataset \n",
        "from keras.datasets import mnist\n",
        "\n",
        "(X_train,y_train),(X_test,y_test) = mnist.load_data()\n",
        "X_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "EIQV0BgTjCPF",
        "outputId": "c86be6bf-cd00-4881-dca9-9c16d4016fc4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[name: \"/device:CPU:0\"\n",
            "device_type: \"CPU\"\n",
            "memory_limit: 268435456\n",
            "locality {\n",
            "}\n",
            "incarnation: 14488226004941186731\n",
            "xla_global_id: -1\n",
            ", name: \"/device:GPU:0\"\n",
            "device_type: \"GPU\"\n",
            "memory_limit: 14465892352\n",
            "locality {\n",
            "  bus_id: 1\n",
            "  links {\n",
            "  }\n",
            "}\n",
            "incarnation: 1547022405826842430\n",
            "physical_device_desc: \"device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\"\n",
            "xla_global_id: 416903419\n",
            "]\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.python.client import device_lib\n",
        "print(device_lib.list_local_devices())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "jMl_4nZmjCPG"
      },
      "outputs": [],
      "source": [
        "img_width, img_height =28,28\n",
        "img_channel = 1\n",
        "img_shape = (img_width, img_height, img_channel)\n",
        "num_classes = 10\n",
        "z_dim = 100"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kiAWf3HljCPH"
      },
      "source": [
        "# Build Generator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "veC9kwOZjCPI",
        "outputId": "3af1ec59-8c8b-43f8-9d1b-bc9420b2fddd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_2 (InputLayer)           [(None, 1)]          0           []                               \n",
            "                                                                                                  \n",
            " embedding (Embedding)          (None, 1, 100)       1000        ['input_2[0][0]']                \n",
            "                                                                                                  \n",
            " input_1 (InputLayer)           [(None, 100)]        0           []                               \n",
            "                                                                                                  \n",
            " flatten (Flatten)              (None, 100)          0           ['embedding[0][0]']              \n",
            "                                                                                                  \n",
            " multiply (Multiply)            (None, 100)          0           ['input_1[0][0]',                \n",
            "                                                                  'flatten[0][0]']                \n",
            "                                                                                                  \n",
            " sequential (Sequential)        (None, 28, 28, 1)    856193      ['multiply[0][0]']               \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 857,193\n",
            "Trainable params: 856,809\n",
            "Non-trainable params: 384\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "from keras.layers import UpSampling2D, Reshape, Activation, Conv2D, BatchNormalization, LeakyReLU, Input, Flatten, multiply\n",
        "from keras.layers import Dense, Embedding\n",
        "from keras.models import Sequential, Model\n",
        "\n",
        "def build_generator():\n",
        "    model = Sequential()\n",
        "    model.add(Dense(128*7*7, activation = 'relu', input_shape = (z_dim, )))\n",
        "    model.add(Reshape((7,7,128)))\n",
        "    model.add(UpSampling2D())\n",
        "    model.add(Conv2D(128, kernel_size = 3, strides = 2, padding = 'same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(LeakyReLU(alpha = 0.02))\n",
        "    model.add(UpSampling2D())\n",
        "    model.add(Conv2D(64, kernel_size = 3, strides = 1, padding = 'same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(LeakyReLU(alpha = 0.02))\n",
        "    model.add(UpSampling2D())\n",
        "    model.add(Conv2D(1, kernel_size = 3 , strides = 1, padding='same'))\n",
        "    model.add(Activation('tanh'))\n",
        "    \n",
        "    z = Input(shape= (z_dim,))\n",
        "    label = Input(shape=(1,), dtype = 'int32')\n",
        "    \n",
        "    label_embedding = Embedding(num_classes, z_dim, input_length = 1)(label)\n",
        "    label_embedding = Flatten()(label_embedding)\n",
        "    joined = multiply([z, label_embedding])\n",
        "    \n",
        "    img = model(joined)\n",
        "    return Model([z, label], img)\n",
        "\n",
        "generator = build_generator()\n",
        "generator.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BXHSuOMSjCPK"
      },
      "source": [
        "# Build Discriminator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "EwAOzHzajCPL",
        "outputId": "400b6841-5df7-463b-b6f0-e024e81384a5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_4 (InputLayer)           [(None, 1)]          0           []                               \n",
            "                                                                                                  \n",
            " embedding_1 (Embedding)        (None, 1, 784)       7840        ['input_4[0][0]']                \n",
            "                                                                                                  \n",
            " flatten_2 (Flatten)            (None, 784)          0           ['embedding_1[0][0]']            \n",
            "                                                                                                  \n",
            " input_3 (InputLayer)           [(None, 28, 28, 1)]  0           []                               \n",
            "                                                                                                  \n",
            " reshape_1 (Reshape)            (None, 28, 28, 1)    0           ['flatten_2[0][0]']              \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)      (None, 28, 28, 2)    0           ['input_3[0][0]',                \n",
            "                                                                  'reshape_1[0][0]']              \n",
            "                                                                                                  \n",
            " sequential_1 (Sequential)      (None, 1)            95905       ['concatenate[0][0]']            \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 103,745\n",
            "Trainable params: 103,297\n",
            "Non-trainable params: 448\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "from keras.layers import Dropout, Concatenate\n",
        "import numpy as np\n",
        "\n",
        "def build_discriminator():\n",
        "    model = Sequential()\n",
        "    model.add(Conv2D(32, kernel_size = 3, strides = 2, input_shape = (28,28,2), padding = 'same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(LeakyReLU(alpha = 0.02))\n",
        "    model.add(Conv2D(64, kernel_size = 3, strides = 2, padding = 'same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(LeakyReLU(alpha = 0.02))\n",
        "    model.add(Conv2D(128, kernel_size = 3, strides = 2, padding = 'same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(LeakyReLU(alpha = 0.02))\n",
        "    model.add(Dropout(0.25))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(1, activation = 'sigmoid'))\n",
        "    \n",
        "    img = Input(shape= (img_shape))\n",
        "    label = Input(shape= (1,), dtype = 'int32')\n",
        "    \n",
        "    label_embedding = Embedding(input_dim = num_classes, output_dim = np.prod(img_shape), input_length = 1)(label)\n",
        "    label_embedding = Flatten()(label_embedding)\n",
        "    label_embedding = Reshape(img_shape)(label_embedding)\n",
        "    \n",
        "    concat = Concatenate(axis = -1)([img, label_embedding])\n",
        "    prediction = model(concat)\n",
        "    return Model([img, label], prediction)\n",
        "\n",
        "discriminator = build_discriminator()\n",
        "discriminator.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZMVu7b7bjCPM"
      },
      "source": [
        "# Compile and Join Model G/D"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "WH_j5RgejCPN"
      },
      "outputs": [],
      "source": [
        "\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "discriminator.compile(loss = 'binary_crossentropy', optimizer = Adam(0.0002, 0.5), metrics = ['accuracy'])\n",
        "\n",
        "z = Input(shape=(z_dim,))\n",
        "label = Input(shape= (1,))\n",
        "img = generator([z,label])\n",
        "\n",
        "discriminator.trainable = False\n",
        "prediction = discriminator([img, label])\n",
        "\n",
        "cgan = Model([z, label], prediction)\n",
        "cgan.compile(loss= 'binary_crossentropy', optimizer = Adam(0.0002, 0.5))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bXRGFNHbjCPO"
      },
      "source": [
        "# Build  a function for training G/D"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "OZiMr8wJjCPO"
      },
      "outputs": [],
      "source": [
        "def train(epochs, batch_size, save_interval):\n",
        "    (X_train, y_train), (_, _) = mnist.load_data()\n",
        "    \n",
        "    X_train = (X_train - 127.5) / 127.5\n",
        "    X_train = np.expand_dims(X_train, axis=3)\n",
        "    \n",
        "    real = np.ones(shape=(batch_size, 1))\n",
        "    fake = np.zeros(shape=(batch_size, 1))\n",
        "    \n",
        "    for iteration in range(epochs):\n",
        "        \n",
        "        idx = np.random.randint(0, X_train.shape[0], batch_size)\n",
        "        imgs, labels = X_train[idx], y_train[idx]\n",
        "        \n",
        "        z = np.random.normal(0, 1, size=(batch_size, z_dim))\n",
        "        gen_imgs = generator.predict([z, labels])\n",
        "        \n",
        "        d_loss_real = discriminator.train_on_batch([imgs, labels], real)\n",
        "        d_loss_fake = discriminator.train_on_batch([gen_imgs, labels], fake)\n",
        "        d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
        "        \n",
        "        z = np.random.normal(0, 1, size=(batch_size, z_dim))\n",
        "        labels = np.random.randint(0, num_classes, batch_size).reshape(-1, 1)\n",
        "        \n",
        "        g_loss = cgan.train_on_batch([z, labels], real)\n",
        "        \n",
        "        if iteration % save_interval == 0:\n",
        "            print('{} [D loss: {}, accuracy: {:.2f}] [G loss: {}]'.format(iteration, d_loss[0], 100 * d_loss[1], g_loss))\n",
        "            save_image(iteration)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "UK4KWX_ejCPP"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "def save_image(epoch):\n",
        "    r, c = 2,5\n",
        "    z = np.random.normal(0,1,(r*c, z_dim))\n",
        "    labels = np.arange(0,10).reshape(-1,1)\n",
        "    gen_image = generator.predict([z,labels])\n",
        "    gen_image = 0.5 * gen_image + 0.5\n",
        "    \n",
        "    fig, axes = plt.subplots(r,c, figsize = (10,10))\n",
        "    count = 0\n",
        "    for i in range(r):\n",
        "        for j in range(c):\n",
        "            axes[i,j].imshow(gen_image[count,:,:,0],cmap = 'gray')\n",
        "            axes[i,j].axis('off')\n",
        "            axes[i,j].set_title(\"Digit: %d\" % labels[count])\n",
        "            count+=1\n",
        "  \n",
        "    plt.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "du28RJK-jCPQ",
        "outputId": "8b44b7ef-019e-4e75-e995-b98f4b3f973c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 [D loss: 0.5720033645629883, accuracy: 67.19] [G loss: 0.6707225441932678]\n",
            "1000 [D loss: 0.00010420813487144187, accuracy: 100.00] [G loss: 0.0003613601147662848]\n",
            "2000 [D loss: 6.773565928597236e-06, accuracy: 100.00] [G loss: 9.45625506574288e-05]\n",
            "3000 [D loss: 5.5201439863594715e-06, accuracy: 100.00] [G loss: 5.09698293171823e-05]\n",
            "4000 [D loss: 1.0951304716400045e-06, accuracy: 100.00] [G loss: 1.846204759203829e-05]\n",
            "5000 [D loss: 2.0888987961598104e-07, accuracy: 100.00] [G loss: 6.378536454576533e-06]\n",
            "6000 [D loss: 6.594668278125937e-08, accuracy: 100.00] [G loss: 2.429586402286077e-06]\n",
            "7000 [D loss: 7.539857449501142e-08, accuracy: 100.00] [G loss: 8.956034434959292e-06]\n",
            "8000 [D loss: 7.439418254762131e-07, accuracy: 100.00] [G loss: 0.0058541130274534225]\n",
            "9000 [D loss: 3.561362902360088e-07, accuracy: 100.00] [G loss: 0.0036372384056448936]\n",
            "10000 [D loss: 1.1941973809825868e-07, accuracy: 100.00] [G loss: 0.0012328296434134245]\n",
            "11000 [D loss: 2.442233704158525e-08, accuracy: 100.00] [G loss: 0.0005092209321446717]\n",
            "12000 [D loss: 4.9222774745061315e-09, accuracy: 100.00] [G loss: 9.359339310321957e-05]\n",
            "13000 [D loss: 2.445926017280442e-09, accuracy: 100.00] [G loss: 6.283484253799543e-05]\n",
            "14000 [D loss: 2.785892405654522e-09, accuracy: 100.00] [G loss: 3.528970410116017e-05]\n",
            "15000 [D loss: 1.4465232345273193e-09, accuracy: 100.00] [G loss: 2.7867334210895933e-05]\n",
            "16000 [D loss: 9.205905482367882e-10, accuracy: 100.00] [G loss: 2.9280530725372955e-05]\n",
            "17000 [D loss: 9.336722506247952e-10, accuracy: 100.00] [G loss: 2.3003043679636903e-05]\n",
            "18000 [D loss: 4.718530149938616e-10, accuracy: 100.00] [G loss: 1.2380342923279386e-05]\n",
            "19000 [D loss: 3.315860225283629e-10, accuracy: 100.00] [G loss: 4.232052106090123e-06]\n",
            "20000 [D loss: 4.701581624022566e-10, accuracy: 100.00] [G loss: 4.056036232213955e-06]\n",
            "21000 [D loss: 1.3910959884011476e-10, accuracy: 100.00] [G loss: 3.4977701943716966e-06]\n",
            "22000 [D loss: 1.2998233392402803e-10, accuracy: 100.00] [G loss: 1.8605854847919545e-06]\n",
            "23000 [D loss: 3.601897252680786e-10, accuracy: 100.00] [G loss: 0.016197003424167633]\n",
            "24000 [D loss: 1.9223525549172393e-10, accuracy: 100.00] [G loss: 0.0011583598097786307]\n",
            "25000 [D loss: 1.525028922588767e-10, accuracy: 100.00] [G loss: 0.0006557923625223339]\n",
            "26000 [D loss: 1.566405893882461e-10, accuracy: 100.00] [G loss: 0.00019695176160894334]\n",
            "27000 [D loss: 7.463977699795343e-11, accuracy: 100.00] [G loss: 0.00012495399278122932]\n",
            "28000 [D loss: 1.1332307661704455e-10, accuracy: 100.00] [G loss: 7.682926661800593e-05]\n",
            "29000 [D loss: 5.317049231456927e-11, accuracy: 100.00] [G loss: 4.5446184230968356e-05]\n",
            "30000 [D loss: 8.907652740419714e-11, accuracy: 100.00] [G loss: 2.8195581762702204e-05]\n",
            "31000 [D loss: 4.525412683475949e-11, accuracy: 100.00] [G loss: 1.697834704827983e-05]\n",
            "32000 [D loss: 7.028764376082464e-11, accuracy: 100.00] [G loss: 6.034787475073244e-06]\n",
            "33000 [D loss: 1.0842161196622513e-10, accuracy: 100.00] [G loss: 2.127208972524386e-06]\n",
            "34000 [D loss: 1.3988066260850474e-10, accuracy: 100.00] [G loss: 2.221539716629195e-06]\n",
            "35000 [D loss: 1.0539961958766497e-10, accuracy: 100.00] [G loss: 1.4901841041137232e-06]\n",
            "36000 [D loss: 1.0521607543556577e-10, accuracy: 100.00] [G loss: 7.446745939887478e-07]\n",
            "37000 [D loss: 5.045687478943961e-11, accuracy: 100.00] [G loss: 5.676118348674208e-07]\n",
            "38000 [D loss: 5.052849284814531e-11, accuracy: 100.00] [G loss: 6.504482144009671e-07]\n",
            "39000 [D loss: 5.5524975242637886e-11, accuracy: 100.00] [G loss: 3.0073363177507417e-07]\n",
            "40000 [D loss: 9.218471819227858e-11, accuracy: 100.00] [G loss: 1.2906397728329466e-07]\n",
            "41000 [D loss: 4.587759686036641e-11, accuracy: 100.00] [G loss: 9.564603686840201e-08]\n",
            "42000 [D loss: 2.985286757378747e-11, accuracy: 100.00] [G loss: 7.196454987479228e-08]\n",
            "43000 [D loss: 4.822807084248204e-11, accuracy: 100.00] [G loss: 7.955589609309754e-08]\n",
            "44000 [D loss: 3.9938820479978876e-11, accuracy: 100.00] [G loss: 6.35905195167652e-08]\n",
            "45000 [D loss: 1.2840504180766654e-10, accuracy: 100.00] [G loss: 5.300777772276888e-08]\n",
            "46000 [D loss: 6.439495811583207e-11, accuracy: 100.00] [G loss: 4.653158214296127e-08]\n",
            "47000 [D loss: 4.0251305760685696e-11, accuracy: 100.00] [G loss: 4.407127818240042e-08]\n",
            "48000 [D loss: 3.77891919145501e-11, accuracy: 100.00] [G loss: 4.73600323402934e-08]\n",
            "49000 [D loss: 5.154641557342243e-11, accuracy: 100.00] [G loss: 3.86563314691557e-08]\n"
          ]
        }
      ],
      "source": [
        "# train network\n",
        "train(50000, 128, 1000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TvStPMtCjCPR"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.2"
    },
    "colab": {
      "name": "Copy of Conditional GAN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}